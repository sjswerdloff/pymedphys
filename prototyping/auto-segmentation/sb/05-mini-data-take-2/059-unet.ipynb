{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import skimage\n",
    "\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes it so any changes in pymedphys is automatically\n",
    "# propagated into the notebook without needing a kernel reset.\n",
    "from IPython.lib.deepreload import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymedphys._experimental.autosegmentation import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.unet(grid_size=64, output_channels=output_channels)  # background, patient, brain, eyes\n",
    "\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_uids = [\n",
    "    path.name for path in pathlib.Path('data').glob('*')\n",
    "]\n",
    "\n",
    "structure_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = len(structure_uids) - 2\n",
    "training_uids = structure_uids[0:split_num]\n",
    "testing_uids = structure_uids[split_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_for_uids(uids):\n",
    "    image_paths = [\n",
    "        str(path) for path in pathlib.Path('data').glob('**/*_image.png')\n",
    "        if not path.parent.name in uids\n",
    "    ]\n",
    "    np.random.shuffle(image_paths)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def mask_paths_from_image_paths(image_paths):\n",
    "    mask_paths = [\n",
    "        f\"{image_path.split('_')[0]}_mask.png\"\n",
    "        for image_path in image_paths\n",
    "    ]\n",
    "    \n",
    "    return mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_paths = get_image_paths_for_uids(training_uids)\n",
    "training_mask_paths = mask_paths_from_image_paths(training_image_paths)\n",
    "\n",
    "testing_image_paths = get_image_paths_for_uids(testing_uids)\n",
    "testing_mask_paths = mask_paths_from_image_paths(testing_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_weights = np.array([\n",
    "#     0.9864694074789978, 0.9251728496022601, 0.0883577429187421\n",
    "# ])[None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalise_mask(png_mask):\n",
    "    normalised_mask = np.round(png_mask / 255).astype(float)\n",
    "    \n",
    "    return normalised_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _remove_mask_weights(weighted_mask):\n",
    "#     return weighted_mask / mask_weights\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_mask = imageio.imread(testing_mask_paths[0])\n",
    "normalised_mask = _normalise_mask(png_mask)\n",
    "plt.imshow(png_mask)\n",
    "plt.show()\n",
    "plt.imshow(normalised_mask)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(normalised_mask[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(normalised_mask[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(normalised_mask[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalise_image(png_image):\n",
    "    normalised_image = png_image[:,:,None].astype(float) / 255\n",
    "    return normalised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = _normalise_image(imageio.imread(testing_image_paths[0]))\n",
    "plt.imshow(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 200\n",
    "\n",
    "def get_dataset(image_paths, mask_paths):\n",
    "    input_arrays = []\n",
    "    output_arrays = []\n",
    "    for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "        input_arrays.append(_normalise_image(imageio.imread(image_path)))\n",
    "        output_arrays.append(_normalise_mask(imageio.imread(mask_path)))\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_arrays, output_arrays))\n",
    "    dataset = dataset.repeat().shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = get_dataset(training_image_paths, training_mask_paths)\n",
    "testing_dataset = get_dataset(testing_image_paths, testing_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in training_dataset.take(1):\n",
    "    sample_image_raw, sample_mask_raw = image, mask\n",
    "\n",
    "has_brain = np.sum(sample_mask_raw[:,:,:,1], axis=(1,2))\n",
    "has_eyes = np.sum(sample_mask_raw[:,:,:,0], axis=(1,2))\n",
    "\n",
    "max_brain_eyes_combo = np.argmax(has_brain * has_eyes)\n",
    "\n",
    "sample_image = sample_image_raw[max_brain_eyes_combo,:,:,:]\n",
    "sample_mask = sample_mask_raw[max_brain_eyes_combo,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sample_mask_raw[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(sample_mask_raw[:,:,:,0]==0) / np.sum(sample_mask_raw[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scharr_operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sch_mag = np.sqrt(sum([scharr(image, axis=i)**2\n",
    "#                        for i in range(image.ndim)]) / image.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_channels(kernel, output_channels, batch_size):\n",
    "    kernel = np.concatenate([kernel[:,:,None],]*output_channels, axis=-1)\n",
    "#     kernel = np.concatenate([kernel[None,:,:,:],]*batch_size, axis=0)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scharr_x = np.array([\n",
    "    [47, 0, -47],\n",
    "    [162, 0, -162],\n",
    "    [47, 0, -47]\n",
    "]).astype(np.float32)\n",
    "scharr_y = scharr_x.T\n",
    "scharr_x = K.constant(scharr_x)\n",
    "scharr_y = K.constant(scharr_y)\n",
    "\n",
    "\n",
    "# scharr_x = _add_channels(scharr_x, output_channels, BATCH_SIZE)\n",
    "# scharr_y = _add_channels(scharr_y, output_channels, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask_raw[0,:,:,2][None,:,:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scharr_x[None,:,:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_sharr_filter(image):\n",
    "    items = []\n",
    "    for i in range(image.shape[-1]):\n",
    "        x = tf.compat.v1.nn.convolution(image[:,:,:,i][:,:,:,None], scharr_x[:,:,None,None], padding=\"VALID\")\n",
    "        y = tf.compat.v1.nn.convolution(image[:,:,:,i][:,:,:,None], scharr_y[:,:,None,None], padding=\"VALID\")\n",
    "        items.append(K.sqrt(x**2 + y**2))\n",
    "        \n",
    "    return K.concatenate(items, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = K.constant(tf.cast(sample_mask_raw, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = _apply_sharr_filter(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.conv1d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _apply_kernel(image, kernel):\n",
    "#     return K.conv2d(image[0:1,:,:,2:], kernel[:,:,None], padding=\"same\", data_format='channels_last', dilation_rate=1, strides=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_dir = _apply_kernel(sample_mask_raw, scharr_x)\n",
    "# y_dir = _apply_kernel(sample_mask_raw, scharr_y)\n",
    "\n",
    "# magnitude = K.sqrt(x_dir**2 + y_dir**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(filtered[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_reference = skimage.filters.scharr(sample_mask_raw[0,:,:,2])\n",
    "plt.imshow(edge_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skimage_scharr_loss(reference, evaluation):\n",
    "    edge_reference = skimage.filters.scharr(reference)\n",
    "    edge_evaluation = skimage.filters.scharr(evaluation)\n",
    "\n",
    "    score = np.sum(np.abs(edge_evaluation - edge_reference)) / np.sum(\n",
    "        edge_evaluation + edge_reference\n",
    "    )\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_weights = [0.98, 0.92, 0.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scharr_loss(reference, evaluation):\n",
    "    edge_reference = _apply_sharr_filter(reference)\n",
    "    edge_evaluation = _apply_sharr_filter(evaluation)\n",
    "\n",
    "    score = 0\n",
    "    for i in range(edge_evaluation.shape[-1]):\n",
    "        score += custom_weights[i] * K.sum(K.abs(edge_evaluation[:,:,:,i] - edge_reference[:,:,:,i]))\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    \n",
    "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
    "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
    "    gradient.\n",
    "    \n",
    "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "    \n",
    "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "    @author: wassname\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_weights = []\n",
    "for i in range(3):\n",
    "    num_of_ones = np.sum(sample_mask_raw[:,:,:,i])\n",
    "    num_of_zeros = np.sum(sample_mask_raw[:,:,:,i]==0)\n",
    "    \n",
    "    one_weight = (1-num_of_ones)/(num_of_ones + num_of_zeros)\n",
    "    zero_weight = (1-num_of_zeros)/(num_of_ones + num_of_zeros)\n",
    "    \n",
    "    cross_entropy_weights.append([one_weight, zero_weight])                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_cross_entropy(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(y_pred.shape[-1]):\n",
    "        one_weight, zero_weight = cross_entropy_weights[i]\n",
    "        b_ce = K.binary_crossentropy(y_true[:,:,:,i], y_pred[:,:,:,i])\n",
    "        \n",
    "        weight_vector = y_true[:,:,:,i] * one_weight + (1 - y_true[:,:,:,i]) * zero_weight\n",
    "        loss += K.mean(weight_vector * b_ce)\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scharr_loss(image, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_class_weight_normalisation = 1/4 * (\n",
    "#     number_of_not_background + number_of_not_patient + number_of_not_brain + number_of_not_eyes)\n",
    "\n",
    "# class_weights = [\n",
    "#     number_of_not_background / total_class_weight_normalisation,\n",
    "#     number_of_not_patient / total_class_weight_normalisation,\n",
    "#     number_of_not_brain / total_class_weight_normalisation,\n",
    "#     number_of_not_eyes / total_class_weight_normalisation\n",
    "# ]\n",
    "\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=weighted_cross_entropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])            \n",
    "        plt.imshow(display_list[i])\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], pred_mask[0]])\n",
    "    else:\n",
    "        display(\n",
    "            [\n",
    "                sample_image, sample_mask,\n",
    "                model.predict(sample_image[tf.newaxis, ...])[0]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(\n",
    "    training_dataset, epochs=1000,\n",
    "    steps_per_epoch=10,\n",
    "    callbacks=[DisplayCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys",
   "language": "python",
   "name": "pymedphys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
