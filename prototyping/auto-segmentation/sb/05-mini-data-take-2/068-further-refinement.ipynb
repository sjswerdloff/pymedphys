{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import skimage\n",
    "\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_for_uids(uids):\n",
    "    image_paths = [\n",
    "        str(path) for path in pathlib.Path('data').glob('**/*_image.png')\n",
    "        if path.parent.name in uids\n",
    "    ]\n",
    "    np.random.shuffle(image_paths)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "\n",
    "def mask_paths_from_image_paths(image_paths):\n",
    "    mask_paths = [\n",
    "        f\"{image_path.split('_')[0]}_mask.png\"\n",
    "        for image_path in image_paths\n",
    "    ]\n",
    "    \n",
    "    return mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_uids = [\n",
    "    path.name for path in pathlib.Path('data').glob('*')\n",
    "]\n",
    "split_num = len(structure_uids) - 2\n",
    "training_uids = structure_uids[0:split_num]\n",
    "testing_uids = structure_uids[split_num:]\n",
    "\n",
    "training_image_paths = get_image_paths_for_uids(training_uids)\n",
    "training_mask_paths = mask_paths_from_image_paths(training_image_paths)\n",
    "\n",
    "testing_image_paths = get_image_paths_for_uids(testing_uids)\n",
    "testing_mask_paths = mask_paths_from_image_paths(testing_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _centre_crop(image):\n",
    "    shape = image.shape\n",
    "    cropped = image[\n",
    "        shape[0]//4:3*shape[0]//4,\n",
    "        shape[1]//4:3*shape[1]//4,\n",
    "        ...\n",
    "    ]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_mask(png_mask):\n",
    "    normalised_mask = png_mask / 255\n",
    "    cropped = _centre_crop(normalised_mask)\n",
    "    \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(png_image):\n",
    "    normalised_image = png_image[:,:,None].astype(float) / 255\n",
    "    cropped = _centre_crop(normalised_image)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(image_paths, mask_paths):\n",
    "    input_arrays = []\n",
    "    output_arrays = []\n",
    "    for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "        input_arrays.append(_process_image(imageio.imread(image_path)))\n",
    "        output_arrays.append(_process_mask(imageio.imread(mask_path)))\n",
    "        \n",
    "    images = tf.cast(np.array(input_arrays), tf.float32)\n",
    "    masks = tf.cast(np.array(output_arrays), tf.float32)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_masks = get_datasets(training_image_paths, training_mask_paths)\n",
    "testing_images, testing_masks = get_datasets(testing_image_paths, testing_mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])            \n",
    "        plt.imshow(display_list[i])\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_brain = np.sum(testing_masks[:,:,:,1], axis=(1,2))\n",
    "has_eyes = np.sum(testing_masks[:,:,:,0], axis=(1,2))\n",
    "\n",
    "brain_sort = 1 - np.argsort(has_brain) / len(has_brain)\n",
    "eyes_sort = 1 - np.argsort(has_eyes) / len(has_eyes)\n",
    "\n",
    "max_combo = np.argmax(brain_sort * eyes_sort * has_brain * has_eyes)\n",
    "\n",
    "sample_image = testing_images[max_combo,:,:,:]\n",
    "sample_mask = testing_masks[max_combo,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = _conv_transpose(x, number_of_filters)\n",
    "    x = _activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=3)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = _activation(x)\n",
    "\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(\n",
    "    x,\n",
    "    fc_channels,\n",
    "    interface_grid_size,\n",
    "    interface_channels,\n",
    "    fc_repeats=2,\n",
    "):\n",
    "    start = x\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        fc_channels, interface_grid_size, padding=\"valid\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "    \n",
    "    for _ in range(fc_repeats):\n",
    "        residual = x\n",
    "        x = _activation(x)\n",
    "        x = tf.keras.layers.Dense(fc_channels)(x)\n",
    "        x = tf.keras.layers.Add()([residual, x])\n",
    "\n",
    "    x = _activation(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(\n",
    "        interface_grid_size * interface_grid_size * interface_channels\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Reshape(\n",
    "        (interface_grid_size, interface_grid_size, interface_channels)\n",
    "    )(x)\n",
    "    \n",
    "    x = tf.keras.layers.Add()([start, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dims = training_masks.shape\n",
    "assert mask_dims[1] == mask_dims[2]\n",
    "grid_size = int(mask_dims[2])\n",
    "output_channels = int(mask_dims[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((grid_size, grid_size, 1))\n",
    "x = inputs\n",
    "skips = []\n",
    "\n",
    "for number_of_filters in [32, 64]:\n",
    "    x, skip = encode(x, number_of_filters)\n",
    "    skips.append(skip)\n",
    "    \n",
    "skips.reverse()\n",
    "\n",
    "x = fully_connected(\n",
    "    x,\n",
    "    fc_channels=256,\n",
    "    interface_grid_size=8,\n",
    "    interface_channels=64,\n",
    "    fc_repeats=2,\n",
    ")\n",
    "\n",
    "for number_of_filters, skip in zip([128, 64], skips):\n",
    "    x = decode(x, skip, number_of_filters)\n",
    "    \n",
    "x = tf.keras.layers.Conv2D(\n",
    "    output_channels,\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction():\n",
    "    display(\n",
    "        [\n",
    "            sample_image, sample_mask,\n",
    "            model.predict(sample_image[None,:,:,:])[0,:,:,:]\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        show_prediction()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "        \n",
    "show_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images, \n",
    "    training_masks,\n",
    "    epochs=100,\n",
    "    validation_data=(testing_images, testing_masks),\n",
    "    callbacks=[DisplayCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints_dir = pathlib.Path('checkpoints')\n",
    "# checkpoints_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights(checkpoints_dir.joinpath('final'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymedphys",
   "language": "python",
   "name": "pymedphys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
