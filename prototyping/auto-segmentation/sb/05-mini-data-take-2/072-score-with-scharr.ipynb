{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi6LRJcDJLRV"
   },
   "source": [
    "# CT scan UNet demo\n",
    "\n",
    "This notebook creates a UNet for a minified dataset of animal CTs.\n",
    "\n",
    "If you are on Google Colab, make this train quicker by swapping to a GPU runtime. This is done by clicking `Runtime`, then `Change runtime type`, then selecting `GPU`:\n",
    "\n",
    "![01](https://github.com/pymedphys/pymedphys/blob/85b8434dc2f11bf20b3a775d4cbd5156108f47ef/prototyping/screenshots/change-to-gpu-01.png?raw=1)\n",
    "\n",
    "![02](https://github.com/pymedphys/pymedphys/blob/85b8434dc2f11bf20b3a775d4cbd5156108f47ef/prototyping/screenshots/change-to-gpu-02.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiSdZ8Q0JLRa"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib.request\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import imageio\n",
    "import skimage.filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s04q2zZJLRb"
   },
   "outputs": [],
   "source": [
    "zip_url = 'https://zenodo.org/record/4448689/files/minified-animal-patient-brain-orbits.zip?download=1'\n",
    "zip_filepath = 'data.zip'\n",
    "\n",
    "data_directory = pathlib.Path('data')\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhErXrpWJLRb",
    "outputId": "7f566af4-68df-4bb7-ff5c-5ed0ba1266ca"
   },
   "outputs": [],
   "source": [
    "dataset_types = [path.name for path in data_directory.glob('*') if path.is_dir()]\n",
    "dataset_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydwJnGwmJLRb"
   },
   "outputs": [],
   "source": [
    "def _load_image(image_path):\n",
    "    png_image = imageio.imread(image_path)\n",
    "    normalised_image = png_image[:,:,None] / 255\n",
    "    \n",
    "    return normalised_image\n",
    "\n",
    "\n",
    "def _load_mask(mask_path):\n",
    "    png_mask = imageio.imread(mask_path)\n",
    "    normalised_mask = png_mask / 255\n",
    "    \n",
    "    return normalised_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGU8fYdkJLRc"
   },
   "outputs": [],
   "source": [
    "def load_dataset_type(dataset_type, shuffle=True):\n",
    "    image_suffix = '_image.png'\n",
    "    mask_suffix = '_mask.png'\n",
    "    \n",
    "    image_paths = list(data_directory.joinpath(dataset_type).glob(f'**/*{image_suffix}'))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(image_paths)\n",
    "    \n",
    "    mask_paths = [\n",
    "        path.parent / path.name.replace(image_suffix, mask_suffix)\n",
    "        for path in image_paths\n",
    "    ]\n",
    "    \n",
    "    image_arrays = [\n",
    "        _load_image(image_path)\n",
    "        for image_path in image_paths\n",
    "    ]\n",
    "    mask_arrays = [\n",
    "        _load_mask(mask_path)\n",
    "        for mask_path in mask_paths\n",
    "    ]\n",
    "        \n",
    "    images = np.array(image_arrays)\n",
    "    masks = np.array(mask_arrays)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiYaFEJWJLRc"
   },
   "outputs": [],
   "source": [
    "training_images, training_masks = load_dataset_type('training')\n",
    "validation_images, validation_masks = load_dataset_type('validation', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ej7bHVJLRc"
   },
   "outputs": [],
   "source": [
    "def _find_image_with_most_variety(images, masks):\n",
    "    has_brain = np.sum(masks[:,:,:,1], axis=(1,2))\n",
    "    has_eyes = np.sum(masks[:,:,:,0], axis=(1,2))\n",
    "\n",
    "    brain_sort = 1 - np.argsort(has_brain) / len(has_brain)\n",
    "    eyes_sort = 1 - np.argsort(has_eyes) / len(has_eyes)\n",
    "\n",
    "    max_combo = np.argmax(brain_sort * eyes_sort * has_brain * has_eyes)\n",
    "\n",
    "    sample_image = images[max_combo,:,:,:]\n",
    "    sample_mask = masks[max_combo,:,:,:]\n",
    "    \n",
    "    return sample_image, sample_mask\n",
    "\n",
    "\n",
    "sample_image, sample_mask = _find_image_with_most_variety(\n",
    "    validation_images, validation_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "A0u1bRevJLRc",
    "outputId": "abd2f7f2-9228-4821-c0a7-4d7b7aa1dea1"
   },
   "outputs": [],
   "source": [
    "def display(image, mask, prediction=None):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Input Image')            \n",
    "    plt.imshow(image[:,:,0])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('True Mask')            \n",
    "    plt.imshow(mask)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    if prediction is None:\n",
    "        try:\n",
    "            prediction = model.predict(image[None, ...])[0, ...]\n",
    "        except NameError:\n",
    "            return\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Mask')            \n",
    "    plt.imshow(prediction)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        display(sample_image, sample_mask)\n",
    "        plt.show()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "    \n",
    "    \n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mh8KP0ctJLRd"
   },
   "outputs": [],
   "source": [
    "def _activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V40Om2B2JLRd"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = _activation(x)\n",
    "\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0YtxC_9JLRd"
   },
   "outputs": [],
   "source": [
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = _conv_transpose(x, number_of_filters)\n",
    "    x = _activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=3)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frZStXWWJLRd"
   },
   "outputs": [],
   "source": [
    "mask_dims = training_masks.shape\n",
    "assert mask_dims[1] == mask_dims[2]\n",
    "grid_size = int(mask_dims[2])\n",
    "output_channels = int(mask_dims[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzufytjWJLRf"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((grid_size, grid_size, 1))\n",
    "x = inputs\n",
    "skips = []\n",
    "\n",
    "for number_of_filters in [32, 64, 128]:\n",
    "    x, skip = encode(x, number_of_filters)\n",
    "    skips.append(skip)\n",
    "    \n",
    "skips.reverse()\n",
    "\n",
    "for number_of_filters, skip in zip([256, 128, 64], skips):\n",
    "    x = decode(x, skip, number_of_filters)\n",
    "    \n",
    "x = tf.keras.layers.Conv2D(\n",
    "    output_channels,\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcnWXRGmJLRf",
    "outputId": "a21f377a-ab4f-47a5-831e-8fecb8e1f5fb"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "EHYE0T1VJLRf",
    "outputId": "3e408e55-67f8-4543-8887-cedd6a7de413"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0TNPQy5AJLRg",
    "outputId": "5e11c36d-4163-460e-acf0-3d3372b395c8"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images, \n",
    "    training_masks,\n",
    "    epochs=20,\n",
    "    validation_data=(validation_images, validation_masks),\n",
    "    callbacks=[DisplayCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8IwPQePKUUr"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_images)\n",
    "\n",
    "\n",
    "for image, mask, prediction in zip(validation_images, validation_masks, predictions):\n",
    "    display(image, mask, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kknvq5TMNBK3"
   },
   "outputs": [],
   "source": [
    "example_patient_mask = validation_masks[0,:,:,2]\n",
    "example_patient_prediction = predictions[0,:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "sLw4S2iONNwf",
    "outputId": "60edfec8-931e-40d4-e197-7b2666de97f9"
   },
   "outputs": [],
   "source": [
    "plt.imshow(validation_images[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "LZHGKI-XM32Z",
    "outputId": "e10535a4-60a3-490e-ba07-98e261e54a0f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_patient_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "nQamYUuBMMrs",
    "outputId": "3ed43ba9-173e-401d-8e3b-c87880ba2b25"
   },
   "outputs": [],
   "source": [
    "plt.imshow(example_patient_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "FTSzw-bBM_tQ",
    "outputId": "a6577032-f24e-4bda-e00e-634ac4602d04"
   },
   "outputs": [],
   "source": [
    "edge_filtered_mask = skimage.filters.scharr(example_patient_mask)\n",
    "plt.imshow(edge_filtered_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "8CzGKPDWNz0Q",
    "outputId": "ba0b4f2d-a557-4476-ee91-ad241b96df1f"
   },
   "outputs": [],
   "source": [
    "edge_filtered_prediction = skimage.filters.scharr(example_patient_prediction)\n",
    "plt.imshow(edge_filtered_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mz6D0PgDN4t-",
    "outputId": "19d3113a-dc0f-4d3f-c782-1e7202b773cb"
   },
   "outputs": [],
   "source": [
    "score = 1 - np.sum(np.abs(edge_filtered_mask - edge_filtered_prediction)) / np.sum(\n",
    "    edge_filtered_mask + edge_filtered_prediction\n",
    ")\n",
    "score  # 1, perfect agreement | 0, no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HL9MYhbZP7MG"
   },
   "outputs": [],
   "source": [
    "def soft_surface_dice(reference, evaluation):\n",
    "    edge_reference = skimage.filters.scharr(reference)\n",
    "    edge_evaluation = skimage.filters.scharr(evaluation)\n",
    "\n",
    "    if np.sum(edge_reference) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    score = np.sum(np.abs(edge_evaluation - edge_reference)) / np.sum(\n",
    "        edge_evaluation + edge_reference\n",
    "    )\n",
    "\n",
    "    return 1 - score\n",
    "\n",
    "\n",
    "labels = ['eyes', 'brain', 'patient']\n",
    "def get_scores(validation_masks, predictions):\n",
    "    scores = collections.defaultdict(lambda: [])\n",
    "    for mask, prediction in zip(validation_masks, predictions):\n",
    "        for i, label in enumerate(labels):\n",
    "            scores[label].append(soft_surface_dice(mask[..., i], prediction[..., i]))\n",
    "\n",
    "    return scores\n",
    "\n",
    "scores = get_scores(validation_masks, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4XZ3emcRoXG",
    "outputId": "8ba616fd-b4fc-4648-8e0a-0ebac885ed9f"
   },
   "outputs": [],
   "source": [
    "np.nanmean(scores['eyes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jrzha3xRpVW",
    "outputId": "eaa2da84-3004-430e-8361-e9f78cb0f972"
   },
   "outputs": [],
   "source": [
    "np.nanmean(scores['brain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrJeRecbRsSL",
    "outputId": "a51afe0c-2545-48dd-93de-ed84bbcaca30"
   },
   "outputs": [],
   "source": [
    "np.nanmean(scores['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5uqJk3YPW07"
   },
   "outputs": [],
   "source": [
    "def display_scores():\n",
    "    predictions = model.predict(validation_images)\n",
    "    scores = get_scores(validation_masks, predictions)\n",
    "\n",
    "    print(f\"Eyes: {round(np.nanmean(scores['eyes']), 4)}\")\n",
    "    print(f\"Brain: {round(np.nanmean(scores['brain']), 4)}\")\n",
    "    print(f\"Patient: {round(np.nanmean(scores['patient']), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwaQGlB_SXXt"
   },
   "outputs": [],
   "source": [
    "class DisplayCallbackWithScores(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        display(sample_image, sample_mask)\n",
    "        plt.show()\n",
    "        display_scores()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "M8ZwpRTQSn7T",
    "outputId": "6448f833-3522-4a31-b473-ac820bf172b7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images, \n",
    "    training_masks,\n",
    "    epochs=100,\n",
    "    validation_data=(validation_images, validation_masks),\n",
    "    callbacks=[DisplayCallbackWithScores()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3G18yNHSngw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
