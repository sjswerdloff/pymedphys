{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi6LRJcDJLRV"
   },
   "source": [
    "# CT scan UNet demo\n",
    "\n",
    "This notebook creates a UNet for a minified dataset of animal CTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiSdZ8Q0JLRa"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import urllib.request\n",
    "import shutil\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s04q2zZJLRb"
   },
   "outputs": [],
   "source": [
    "zip_url = 'https://zenodo.org/record/4448689/files/minified-animal-patient-brain-orbits.zip?download=1'\n",
    "zip_filepath = 'data.zip'\n",
    "\n",
    "data_directory = pathlib.Path('data')\n",
    "\n",
    "if not data_directory.exists():\n",
    "    urllib.request.urlretrieve(zip_url, zip_filepath)\n",
    "    shutil.unpack_archive(zip_filepath, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhErXrpWJLRb",
    "outputId": "31dd2fcb-50a7-45d3-b51e-68a944a3fd00"
   },
   "outputs": [],
   "source": [
    "dataset_types = [path.name for path in data_directory.glob('*') if path.is_dir()]\n",
    "dataset_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydwJnGwmJLRb"
   },
   "outputs": [],
   "source": [
    "def _load_image(image_path):\n",
    "    png_image = imageio.imread(image_path)\n",
    "    normalised_image = png_image[:,:,None] / 255\n",
    "    \n",
    "    return normalised_image\n",
    "\n",
    "\n",
    "def _load_mask(mask_path):\n",
    "    png_mask = imageio.imread(mask_path)\n",
    "    normalised_mask = png_mask / 255\n",
    "    \n",
    "    return normalised_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGU8fYdkJLRc"
   },
   "outputs": [],
   "source": [
    "def load_dataset_type(dataset_type, shuffle=True, load_masks=True):\n",
    "    image_suffix = '_image.png'\n",
    "    mask_suffix = '_mask.png'\n",
    "    \n",
    "    dataset_type_directory = data_directory.joinpath(dataset_type)\n",
    "    \n",
    "    image_paths = list(dataset_type_directory.glob(f'**/*{image_suffix}'))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(image_paths)\n",
    "        \n",
    "    uids = [\n",
    "        (path.parent.name, path.name.replace(image_suffix, ''))\n",
    "        for path in image_paths\n",
    "    ]\n",
    "    \n",
    "    image_arrays = [\n",
    "        _load_image(image_path)\n",
    "        for image_path in image_paths\n",
    "    ]\n",
    "    images = np.array(image_arrays)\n",
    "    \n",
    "    if not load_masks:\n",
    "        return uids, images\n",
    "    \n",
    "    mask_paths = [\n",
    "        str(dataset_type_directory.joinpath(uid[0], uid[1])) + mask_suffix\n",
    "        for uid in uids\n",
    "    ]\n",
    "    mask_arrays = [\n",
    "        _load_mask(mask_path)\n",
    "        for mask_path in mask_paths\n",
    "    ]\n",
    "    masks = np.array(mask_arrays)\n",
    "    \n",
    "    return uids, images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiYaFEJWJLRc"
   },
   "outputs": [],
   "source": [
    "_, training_images, training_masks = load_dataset_type('training')\n",
    "_, validation_images, validation_masks = load_dataset_type('validation', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4ej7bHVJLRc"
   },
   "outputs": [],
   "source": [
    "def _find_image_with_most_variety(images, masks):\n",
    "    has_brain = np.sum(masks[:,:,:,1], axis=(1,2))\n",
    "    has_eyes = np.sum(masks[:,:,:,0], axis=(1,2))\n",
    "\n",
    "    brain_sort = 1 - np.argsort(has_brain) / len(has_brain)\n",
    "    eyes_sort = 1 - np.argsort(has_eyes) / len(has_eyes)\n",
    "\n",
    "    max_combo = np.argmax(brain_sort * eyes_sort * has_brain * has_eyes)\n",
    "\n",
    "    sample_image = images[max_combo,:,:,:]\n",
    "    sample_mask = masks[max_combo,:,:,:]\n",
    "    \n",
    "    return sample_image, sample_mask\n",
    "\n",
    "\n",
    "sample_image, sample_mask = _find_image_with_most_variety(\n",
    "    validation_images, validation_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "A0u1bRevJLRc",
    "outputId": "b3a7679a-09c9-4fa0-a4a4-09241b02c697"
   },
   "outputs": [],
   "source": [
    "def display(image, mask, prediction=None):\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Input Image')            \n",
    "    plt.imshow(image[:,:,0])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('True Mask')            \n",
    "    plt.imshow(mask)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    if prediction is None:\n",
    "        try:\n",
    "            prediction = model.predict(image[None, ...])[0, ...]\n",
    "        except NameError:\n",
    "            return\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Mask')            \n",
    "    plt.imshow(prediction)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        display(sample_image, sample_mask)\n",
    "        plt.show()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "    \n",
    "    \n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mh8KP0ctJLRd"
   },
   "outputs": [],
   "source": [
    "def _activation(x):\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _convolution(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        number_of_filters, kernel_size, padding=\"same\", kernel_initializer=\"he_normal\"\n",
    "    )(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv_transpose(x, number_of_filters, kernel_size=3):\n",
    "    x = tf.keras.layers.Conv2DTranspose(\n",
    "        number_of_filters,\n",
    "        kernel_size,\n",
    "        strides=2,\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "    )(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V40Om2B2JLRd"
   },
   "outputs": [],
   "source": [
    "def encode(\n",
    "    x,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "    skip = x\n",
    "\n",
    "    x = tf.keras.layers.MaxPool2D()(x)\n",
    "    x = _activation(x)\n",
    "\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0YtxC_9JLRd"
   },
   "outputs": [],
   "source": [
    "def decode(\n",
    "    x,\n",
    "    skip,\n",
    "    number_of_filters,\n",
    "    number_of_convolutions=2,\n",
    "):\n",
    "    x = _conv_transpose(x, number_of_filters)\n",
    "    x = _activation(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([skip, x], axis=3)\n",
    "\n",
    "    for _ in range(number_of_convolutions):\n",
    "        x = _convolution(x, number_of_filters)\n",
    "        x = _activation(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frZStXWWJLRd"
   },
   "outputs": [],
   "source": [
    "mask_dims = training_masks.shape\n",
    "assert mask_dims[1] == mask_dims[2]\n",
    "grid_size = int(mask_dims[2])\n",
    "output_channels = int(mask_dims[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzufytjWJLRf"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((grid_size, grid_size, 1))\n",
    "x = inputs\n",
    "skips = []\n",
    "\n",
    "for number_of_filters in [32, 64, 128]:\n",
    "    x, skip = encode(x, number_of_filters)\n",
    "    skips.append(skip)\n",
    "    \n",
    "skips.reverse()\n",
    "\n",
    "for number_of_filters, skip in zip([256, 128, 64], skips):\n",
    "    x = decode(x, skip, number_of_filters)\n",
    "    \n",
    "x = tf.keras.layers.Conv2D(\n",
    "    output_channels,\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    padding=\"same\",\n",
    "    kernel_initializer=\"he_normal\",\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcnWXRGmJLRf"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHYE0T1VJLRf"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.Precision()\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0TNPQy5AJLRg"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_images, \n",
    "    training_masks,\n",
    "    epochs=20,\n",
    "    validation_data=(validation_images, validation_masks),\n",
    "    callbacks=[DisplayCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8IwPQePKUUr"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_images)\n",
    "\n",
    "image_combos = list(zip(validation_images, validation_masks, predictions))\n",
    "num_to_display = 15\n",
    "\n",
    "for image, mask, prediction in image_combos[0:num_to_display]:\n",
    "    display(image, mask, prediction)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0zJw7nWbHyt"
   },
   "outputs": [],
   "source": [
    "hold_out_uids, hold_out_images = load_dataset_type('hold-out', load_masks=False, shuffle=False)\n",
    "hold_out_predictions = model.predict(hold_out_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6ozxM4ZbHyt"
   },
   "outputs": [],
   "source": [
    "def _scale_images(image):\n",
    "    scaled = image * 255\n",
    "    scaled = scaled.astype(np.uint8)\n",
    "    \n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YoL3zLzAbHyt"
   },
   "outputs": [],
   "source": [
    "output_directory = pathlib.Path('output')\n",
    "\n",
    "for uids, image, prediction in zip(hold_out_uids, hold_out_images, hold_out_predictions):\n",
    "    studyset_uid_directory = output_directory.joinpath(uids[0])\n",
    "    studyset_uid_directory.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    scaled_image = _scale_images(image)\n",
    "    scaled_prediction = _scale_images(prediction)\n",
    "    \n",
    "    common_filepath_start = str(studyset_uid_directory.joinpath(uids[1]))\n",
    "    \n",
    "    image_filepath = common_filepath_start + '_image.png'\n",
    "    prediction_filepath = common_filepath_start + '_prediction.png'\n",
    "    \n",
    "    imageio.imsave(image_filepath, scaled_image)\n",
    "    imageio.imsave(prediction_filepath, scaled_prediction)\n",
    "\n",
    "    \n",
    "shutil.make_archive(output_directory.name, 'zip', output_directory)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "unet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
